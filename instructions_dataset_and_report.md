# Dataset & Report Generation (CPU + CUDA)

## Objective
Produce:
- **~200MB CPU code dataset**
- **~200MB CUDA code dataset**
- **A short markdown report** for the chief scientist introducing **JIT**, **IR**, **NVIDIA Warp**, and summarizing the current dataset(s).

The datasets should be generated by reproducing and selecting the best production pipeline from existing `cursor/*` branches, then scaling generation until the byte-size targets are reached.

---

## File Structure (create as needed)

```
/
├── instructions_dataset_and_report.md   # This file (read-only reference)
├── DATASET_STATE.md                     # CRITICAL: progress + exact next action
├── code/                                # Production code (copied/merged from best branch)
├── data/
│   ├── samples/                         # ≤100 small samples OK for git
│   └── production/                      # LARGE outputs (git-ignored)
│       ├── cpu/                         # ~200MB target
│       └── cuda/                        # ~200MB target
└── reports/
    ├── dataset_report.md                # Chief scientist report
    └── dataset_stats.json               # Size + counts + basic stats
```

---

## State Management Protocol

### On Session Start
1. Read `DATASET_STATE.md` (create if missing)
2. Resume from the documented **Next Action**

### On Session End
1. Update `DATASET_STATE.md` with:
   - Current phase/task
   - Exact next action (specific command + paths)
   - Blockers (tooling, missing GPU/CUDA toolkit, etc.)
   - Session log summary (1-3 bullets)
2. Ensure the repo is left in a **working** state (generation commands runnable)

### `DATASET_STATE.md` Template
```markdown
# Dataset Generation State
- **Phase**: P1/P2/P3
- **Task**: [short name]
- **Status**: in_progress | blocked | ready_for_next | completed

## Next Action
[exact command(s) + file paths]

## Blockers (if any)
- [blocker]: [what was tried / what’s needed]

## Session Log
- [date/session]: [what changed / what was produced]
```

---

## Phases

### P1: CPU Dataset Production
**Goal**: Select best CPU-capable pipeline and generate **~200MB** of CPU dataset.

**Workflow**
1. **Study candidate branches**:
   - Prioritize `origin/cursor/agent-work-merge-process-*`
   - Confirm presence of: generator, pipeline/batch generator, validation, and stable JSON schema.
2. **Reproduce**: run a small batch locally (e.g., 10–100 samples) and verify:
   - Files are valid JSON
   - Fields include at minimum: kernel name/id, python source, extracted IR/code, and device/backend metadata
3. **Pick one best branch** as the production base:
   - Criteria: reliability, clear CLI, validation tooling, deterministic naming, and dataset schema clarity
4. **Scale generation** iteratively until `data/production/cpu/` reaches **~200MB**:
   - Prefer size-targeted stopping (bytes) over only count-based stopping
   - Write generation stats (`reports/dataset_stats.json`)
5. **Keep large data out of git**:
   - Add `data/production/**` to `.gitignore`

**Done when**
- `data/production/cpu/` total size is **≥ 200MB**
- A small representative subset (≤100) is available under `data/samples/` for review
- Stats file exists and matches disk totals

---

### P2: CUDA Dataset Production
**Goal**: Generate **~200MB** of CUDA dataset in the **same schema**, with CUDA-specific extracted code/IR where possible.

**Notes / Constraints**
- This environment may not have a GPU or CUDA toolkit. The pipeline must:
  - Either (A) extract CUDA code/IR without executing on GPU (preferred), or
  - (B) support running on a real GPU later with clear commands.

**Workflow**
1. Extend the extractor/pipeline to accept a **backend/device selector** (e.g., `--device cpu|cuda`)
2. Ensure kernel coverage across all generator types still works under CUDA mode
3. Generate into `data/production/cuda/` until **≥ 200MB**
4. Record limitations in stats/report (e.g., “CUDA codegen-only, not executed here”)

**Done when**
- `data/production/cuda/` total size is **≥ 200MB**
- CUDA dataset samples validate and load

---

### P3: Report for Chief Scientist
**Goal**: Produce a concise markdown report at `reports/dataset_report.md`.

**Must include**
- What JIT compilation is (1–2 short paragraphs)
- What IR is, and why we extract it for training
- What NVIDIA Warp is and how it fits (Python kernels → JIT → generated code/IR)
- Current dataset summary:
  - CPU: size, count, schema
  - CUDA: size, count, schema
  - Known limitations / reproduction commands

**Done when**
- `reports/dataset_report.md` exists and is readable in <3 minutes
- `reports/dataset_stats.json` exists and matches actual outputs

---

## Validation Protocol
Before claiming a phase complete:
1. Run generation for a small count (10–50) and validate all outputs load as JSON
2. Run any included validation script(s) over `data/samples/`
3. Confirm size targets using disk usage (`du`) and record exact totals in stats JSON

---

## Anti-Patterns (Avoid)
- ❌ Committing or versioning the full 200MB+ datasets in git
- ❌ Changing dataset schema mid-generation without documenting versioning
- ❌ CUDA generation that silently falls back to CPU without recording it


{
  "python_source": "@wp.kernel\ndef mat_kaymjz(m: wp.array(dtype=wp.mat22), v: wp.array(dtype=wp.vec2), out: wp.array(dtype=wp.vec2)):\n    tid = wp.tid()\n    out[tid] = m[tid] * v[tid]\n",
  "cuda_ir": "void mat_kaymjz_0a4d18f2_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::mat_t<2, 2, wp::float32>> var_m,\n    wp::array_t<wp::vec_t<2, wp::float32>> var_v,\n    wp::array_t<wp::vec_t<2, wp::float32>> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::mat_t<2, 2, wp::float32>* var_1;\n        wp::vec_t<2, wp::float32>* var_2;\n        wp::vec_t<2, wp::float32> var_3;\n        wp::mat_t<2, 2, wp::float32> var_4;\n        wp::vec_t<2, wp::float32> var_5;\n        //---------\n        // forward\n        // def mat_kaymjz(m: wp.array(dtype=wp.mat22), v: wp.array(dtype=wp.vec2), out: wp.array(dtype=wp.vec2)):       <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // out[tid] = m[tid] * v[tid]                                                             <L 6>\n        var_1 = wp::address(var_m, var_0);\n        var_2 = wp::address(var_v, var_0);\n        var_4 = wp::load(var_1);\n        var_5 = wp::load(var_2);\n        var_3 = wp::mul(var_4, var_5);\n        wp::array_store(var_out, var_0, var_3);\n    }\n}",
  "metadata": {
    "kernel_name": "mat_kaymjz",
    "category": "matrix",
    "description": "Matrix-vector multiply (wp.mat22 * wp.vec2)",
    "device": "cuda",
    "seed": 10404,
    "cuda_patterns_verified": true,
    "mat_type": "wp.mat22",
    "operation": "mat_vec"
  }
}
{
  "python_source": "@wp.kernel\ndef vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):\n    tid = wp.tid()\n    out[tid] = wp.length(a[tid])\n",
  "cpu_forward": "void vec_xaylku_a5b820f5_cpu_kernel_forward(\n    wp::launch_bounds_t dim,\n    size_t task_index,\n    wp_args_vec_xaylku_a5b820f5 *_wp_args)\n{\n    //---------\n    // argument vars\n    wp::array_t<wp::vec_t<3, wp::float32>> var_a = _wp_args->a;\n    wp::array_t<wp::vec_t<3, wp::float32>> var_b = _wp_args->b;\n    wp::array_t<wp::float32> var_out = _wp_args->out;\n    //---------\n    // primal vars\n    wp::int32 var_0;\n    wp::vec_t<3, wp::float32>* var_1;\n    wp::float32 var_2;\n    wp::vec_t<3, wp::float32> var_3;\n    //---------\n    // forward\n    // def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):       <L 4>\n    // tid = wp.tid()                                                                         <L 5>\n    var_0 = builtin_tid1d();\n    // out[tid] = wp.length(a[tid])                                                           <L 6>\n    var_1 = wp::address(var_a, var_0);\n    var_3 = wp::load(var_1);\n    var_2 = wp::length(var_3);\n    wp::array_store(var_out, var_0, var_2);\n}",
  "cpu_backward": "void vec_xaylku_a5b820f5_cpu_kernel_backward(\n    wp::launch_bounds_t dim,\n    size_t task_index,\n    wp_args_vec_xaylku_a5b820f5 *_wp_args,\n    wp_args_vec_xaylku_a5b820f5 *_wp_adj_args)\n{\n    //---------\n    // argument vars\n    wp::array_t<wp::vec_t<3, wp::float32>> var_a = _wp_args->a;\n    wp::array_t<wp::vec_t<3, wp::float32>> var_b = _wp_args->b;\n    wp::array_t<wp::float32> var_out = _wp_args->out;\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_a = _wp_adj_args->a;\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_b = _wp_adj_args->b;\n    wp::array_t<wp::float32> adj_out = _wp_adj_args->out;\n    //---------\n    // primal vars\n    wp::int32 var_0;\n    wp::vec_t<3, wp::float32>* var_1;\n    wp::float32 var_2;\n    wp::vec_t<3, wp::float32> var_3;\n    //---------\n    // dual vars\n    wp::int32 adj_0 = {};\n    wp::vec_t<3, wp::float32> adj_1 = {};\n    wp::float32 adj_2 = {};\n    wp::vec_t<3, wp::float32> adj_3 = {};\n    //---------\n    // forward\n    // def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):       <L 4>\n    // tid = wp.tid()                                                                         <L 5>\n    var_0 = builtin_tid1d();\n    // out[tid] = wp.length(a[tid])                                                           <L 6>\n    var_1 = wp::address(var_a, var_0);\n    var_3 = wp::load(var_1);\n    var_2 = wp::length(var_3);\n    // wp::array_store(var_out, var_0, var_2);\n    //---------\n    // reverse\n    wp::adj_array_store(var_out, var_0, var_2, adj_out, adj_0, adj_2);\n    wp::adj_length(var_3, var_2, adj_1, adj_2);\n    wp::adj_address(var_a, var_0, adj_a, adj_0, adj_1);\n    // adj: out[tid] = wp.length(a[tid])                                                      <L 6>\n    // adj: tid = wp.tid()                                                                    <L 5>\n    // adj: def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):  <L 4>\n    return;\n}",
  "cuda_forward": "void vec_xaylku_a5b820f5_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_a,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_b,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::vec_t<3, wp::float32>* var_1;\n        wp::float32 var_2;\n        wp::vec_t<3, wp::float32> var_3;\n        //---------\n        // forward\n        // def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):       <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // out[tid] = wp.length(a[tid])                                                           <L 6>\n        var_1 = wp::address(var_a, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::length(var_3);\n        wp::array_store(var_out, var_0, var_2);\n    }\n}",
  "cuda_backward": "void vec_xaylku_a5b820f5_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_a,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_b,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_a,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_b,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::vec_t<3, wp::float32>* var_1;\n        wp::float32 var_2;\n        wp::vec_t<3, wp::float32> var_3;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::vec_t<3, wp::float32> adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::vec_t<3, wp::float32> adj_3 = {};\n        //---------\n        // forward\n        // def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):       <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // out[tid] = wp.length(a[tid])                                                           <L 6>\n        var_1 = wp::address(var_a, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::length(var_3);\n        // wp::array_store(var_out, var_0, var_2);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_2, adj_out, adj_0, adj_2);\n        wp::adj_length(var_3, var_2, adj_1, adj_2);\n        wp::adj_address(var_a, var_0, adj_a, adj_0, adj_1);\n        // adj: out[tid] = wp.length(a[tid])                                                      <L 6>\n        // adj: tid = wp.tid()                                                                    <L 5>\n        // adj: def vec_xaylku(a: wp.array(dtype=wp.vec3), b: wp.array(dtype=wp.vec3), out: wp.array(dtype=float)):  <L 4>\n        continue;\n    }\n}",
  "metadata": {
    "kernel_name": "vec_xaylku",
    "category": "vector",
    "description": "Vector kernel: length on wp.vec3",
    "has_backward": true,
    "vec_type": "wp.vec3",
    "operation": "length",
    "seed": 2863
  }
}
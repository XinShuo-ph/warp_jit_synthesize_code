{
  "python_source": "@wp.kernel\ndef arith_jumkjg(a: wp.array(dtype=float), b: wp.array(dtype=float), c: wp.array(dtype=float)):\n    tid = wp.tid()\n    var_0 = wp.abs(a[tid])\n    c[tid] = var_0\n",
  "cuda_forward": "__global__ void arith_jumkjg_b0234e86_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_a,\n    wp::array_t<wp::float32> var_b,\n    wp::array_t<wp::float32> var_c)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        //---------\n        // forward\n        // def arith_jumkjg(a: wp.array(dtype=float), b: wp.array(dtype=float), c: wp.array(dtype=float)):       <L 52>\n        // tid = wp.tid()                                                                         <L 53>\n        var_0 = builtin_tid1d();\n        // var_0 = wp.abs(a[tid])                                                                 <L 54>\n        var_1 = wp::address(var_a, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::abs(var_3);\n        // c[tid] = var_0                                                                         <L 55>\n        wp::array_store(var_c, var_0, var_2);\n    }\n}",
  "metadata": {
    "kernel_name": "arith_jumkjg",
    "category": "arithmetic",
    "description": "Arithmetic kernel with 1 operations",
    "device": "cuda",
    "num_ops": 1,
    "seed": 16339
  }
}
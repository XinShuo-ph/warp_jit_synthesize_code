{
  "id": "66349416c3d7",
  "kernel_name": "vec_qkuafk",
  "kernel_type": "vector",
  "python_source": "@wp.kernel\ndef vec_qkuafk(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):\n    tid = wp.tid()\n    dt = -7.67\n    new_vel = vel[tid] + acc[tid] * dt\n    pos[tid] = pos[tid] + new_vel * dt\n    vel[tid] = new_vel\n",
  "cuda_ir_forward": "void vec_qkuafk_6ae99a79_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 7.67;\n        const wp::float32 var_2 = -7.67;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32>* var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32> var_8;\n        wp::vec_t<3, wp::float32>* var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        wp::vec_t<3, wp::float32> var_12;\n        //---------\n        // forward\n        // def vec_qkuafk(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 140>\n        // tid = wp.tid()                                                                         <L 141>\n        var_0 = builtin_tid1d();\n        // dt = -7.67                                                                             <L 142>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 143>\n        var_3 = wp::address(var_vel, var_0);\n        var_4 = wp::address(var_acc, var_0);\n        var_6 = wp::load(var_4);\n        var_5 = wp::mul(var_6, var_2);\n        var_8 = wp::load(var_3);\n        var_7 = wp::add(var_8, var_5);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 144>\n        var_9 = wp::address(var_pos, var_0);\n        var_10 = wp::mul(var_7, var_2);\n        var_12 = wp::load(var_9);\n        var_11 = wp::add(var_12, var_10);\n        wp::array_store(var_pos, var_0, var_11);\n        // vel[tid] = new_vel                                                                     <L 145>\n        wp::array_store(var_vel, var_0, var_7);\n    }\n}",
  "cuda_ir_backward": "",
  "cuda_ir_full": "\n#define WP_TILE_BLOCK_DIM 256\n#define WP_NO_CRT\n#include \"builtin.h\"\n\n// Map wp.breakpoint() to a device brkpt at the call site so cuda-gdb attributes the stop to the generated .cu line\n#if defined(__CUDACC__) && !defined(_MSC_VER)\n#define __debugbreak() __brkpt()\n#endif\n\n// avoid namespacing of float type for casting to float type, this is to avoid wp::float(x), which is not valid in C++\n#define float(x) cast_float(x)\n#define adj_float(x, adj_x, adj_ret) adj_cast_float(x, adj_x, adj_ret)\n\n#define int(x) cast_int(x)\n#define adj_int(x, adj_x, adj_ret) adj_cast_int(x, adj_x, adj_ret)\n\n#define builtin_tid1d() wp::tid(_idx, dim)\n#define builtin_tid2d(x, y) wp::tid(x, y, _idx, dim)\n#define builtin_tid3d(x, y, z) wp::tid(x, y, z, _idx, dim)\n#define builtin_tid4d(x, y, z, w) wp::tid(x, y, z, w, _idx, dim)\n\n#define builtin_block_dim() wp::block_dim()\n\n\n\nextern \"C\" __global__ void multicond_ricuhr_63a41ecb_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 3.75;\n        const wp::float32 var_5 = -3.75;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.33;\n        const wp::float32 var_10 = -3.33;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // forward\n        // def multicond_ricuhr(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 6>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -3.75:                                                                        <L 7>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 8>\n            var_8 = wp::mul(var_2, var_7);\n            wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.33:                                                                  <L 9>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 10>\n                var_13 = wp::mul(var_2, var_12);\n                wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 12>\n                var_15 = wp::mul(var_2, var_14);\n                wp::array_store(var_out, var_0, var_15);\n            }\n        }\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_ricuhr_63a41ecb_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 3.75;\n        const wp::float32 var_5 = -3.75;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.33;\n        const wp::float32 var_10 = -3.33;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        bool adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        bool adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::float32 adj_13 = {};\n        wp::float32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        //---------\n        // forward\n        // def multicond_ricuhr(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 6>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -3.75:                                                                        <L 7>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 8>\n            var_8 = wp::mul(var_2, var_7);\n            // wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.33:                                                                  <L 9>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 10>\n                var_13 = wp::mul(var_2, var_12);\n                // wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 12>\n                var_15 = wp::mul(var_2, var_14);\n                // wp::array_store(var_out, var_0, var_15);\n            }\n        }\n        //---------\n        // reverse\n        if (!var_6) {\n            if (!var_11) {\n                wp::adj_array_store(var_out, var_0, var_15, adj_out, adj_0, adj_15);\n                wp::adj_mul(var_2, var_14, adj_2, adj_14, adj_15);\n                // adj: out[tid] = val * 2.0                                                      <L 12>\n            }\n            if (var_11) {\n                wp::adj_array_store(var_out, var_0, var_13, adj_out, adj_0, adj_13);\n                wp::adj_mul(var_2, var_12, adj_2, adj_12, adj_13);\n                // adj: out[tid] = val * 1.0                                                      <L 10>\n            }\n            // adj: elif val < -3.33:                                                             <L 9>\n        }\n        if (var_6) {\n            wp::adj_array_store(var_out, var_0, var_8, adj_out, adj_0, adj_8);\n            wp::adj_mul(var_2, var_7, adj_2, adj_7, adj_8);\n            // adj: out[tid] = val * 0.5                                                          <L 8>\n        }\n        // adj: if val < -3.75:                                                                   <L 7>\n        wp::adj_copy(var_3, adj_1, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = x[tid]                                                                      <L 6>\n        // adj: tid = wp.tid()                                                                    <L 5>\n        // adj: def multicond_ricuhr(x: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 4>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void arith_pewqql_cd6ac8ca_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_a,\n    wp::array_t<wp::float32> var_b,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        const wp::float32 var_6 = 1.02;\n        const wp::float32 var_7 = -1.02;\n        wp::float32 var_8;\n        //---------\n        // forward\n        // def arith_pewqql(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 44>\n        // tid = wp.tid()                                                                         <L 45>\n        var_0 = builtin_tid1d();\n        // out[tid] = (a[tid] * b[tid]) - -1.02                                                   <L 46>\n        var_1 = wp::address(var_a, var_0);\n        var_2 = wp::address(var_b, var_0);\n        var_4 = wp::load(var_1);\n        var_5 = wp::load(var_2);\n        var_3 = wp::mul(var_4, var_5);\n        var_8 = wp::sub(var_3, var_7);\n        wp::array_store(var_out, var_0, var_8);\n    }\n}\n\n\n\nextern \"C\" __global__ void arith_pewqql_cd6ac8ca_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_a,\n    wp::array_t<wp::float32> var_b,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_a,\n    wp::array_t<wp::float32> adj_b,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        const wp::float32 var_6 = 1.02;\n        const wp::float32 var_7 = -1.02;\n        wp::float32 var_8;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        wp::float32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        //---------\n        // forward\n        // def arith_pewqql(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 44>\n        // tid = wp.tid()                                                                         <L 45>\n        var_0 = builtin_tid1d();\n        // out[tid] = (a[tid] * b[tid]) - -1.02                                                   <L 46>\n        var_1 = wp::address(var_a, var_0);\n        var_2 = wp::address(var_b, var_0);\n        var_4 = wp::load(var_1);\n        var_5 = wp::load(var_2);\n        var_3 = wp::mul(var_4, var_5);\n        var_8 = wp::sub(var_3, var_7);\n        // wp::array_store(var_out, var_0, var_8);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_8, adj_out, adj_0, adj_8);\n        wp::adj_sub(var_3, var_7, adj_3, adj_7, adj_8);\n        wp::adj_mul(var_4, var_5, adj_1, adj_2, adj_3);\n        wp::adj_address(var_b, var_0, adj_b, adj_0, adj_2);\n        wp::adj_address(var_a, var_0, adj_a, adj_0, adj_1);\n        // adj: out[tid] = (a[tid] * b[tid]) - -1.02                                              <L 46>\n        // adj: tid = wp.tid()                                                                    <L 45>\n        // adj: def arith_pewqql(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):  <L 44>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_qibnxl_6ce0ca04_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def scalar_qibnxl(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 15>\n        // tid = wp.tid()                                                                         <L 16>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 17>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        wp::array_store(var_out, var_0, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_qibnxl_6ce0ca04_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out,\n    wp::float32 adj_scale,\n    wp::float32 adj_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def scalar_qibnxl(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 15>\n        // tid = wp.tid()                                                                         <L 16>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 17>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        // wp::array_store(var_out, var_0, var_4);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_4, adj_out, adj_0, adj_4);\n        wp::adj_add(var_2, var_offset, adj_2, adj_offset, adj_4);\n        wp::adj_add(var_3, var_scale, adj_1, adj_scale, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: out[tid] = x[tid] + scale + offset                                                <L 17>\n        // adj: tid = wp.tid()                                                                    <L 16>\n        // adj: def scalar_qibnxl(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):  <L 15>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void math_flkhpn_74964cfe_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        const wp::float32 var_2 = 9.38;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // forward\n        // def math_flkhpn(x: wp.array(dtype=float), out: wp.array(dtype=float)):                 <L 121>\n        // tid = wp.tid()                                                                         <L 122>\n        var_0 = builtin_tid1d();\n        // val = wp.abs(x[tid] * 9.38)                                                            <L 123>\n        var_1 = wp::address(var_x, var_0);\n        var_4 = wp::load(var_1);\n        var_3 = wp::mul(var_4, var_2);\n        var_5 = wp::abs(var_3);\n        // out[tid] = wp.exp(val)                                                                 <L 124>\n        var_6 = wp::exp(var_5);\n        wp::array_store(var_out, var_0, var_6);\n    }\n}\n\n\n\nextern \"C\" __global__ void math_flkhpn_74964cfe_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        const wp::float32 var_2 = 9.38;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        wp::float32 adj_6 = {};\n        //---------\n        // forward\n        // def math_flkhpn(x: wp.array(dtype=float), out: wp.array(dtype=float)):                 <L 121>\n        // tid = wp.tid()                                                                         <L 122>\n        var_0 = builtin_tid1d();\n        // val = wp.abs(x[tid] * 9.38)                                                            <L 123>\n        var_1 = wp::address(var_x, var_0);\n        var_4 = wp::load(var_1);\n        var_3 = wp::mul(var_4, var_2);\n        var_5 = wp::abs(var_3);\n        // out[tid] = wp.exp(val)                                                                 <L 124>\n        var_6 = wp::exp(var_5);\n        // wp::array_store(var_out, var_0, var_6);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_6, adj_out, adj_0, adj_6);\n        wp::adj_exp(var_5, var_6, adj_5, adj_6);\n        // adj: out[tid] = wp.exp(val)                                                            <L 124>\n        wp::adj_abs(var_3, adj_3, adj_5);\n        wp::adj_mul(var_4, var_2, adj_1, adj_2, adj_3);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = wp.abs(x[tid] * 9.38)                                                       <L 123>\n        // adj: tid = wp.tid()                                                                    <L 122>\n        // adj: def math_flkhpn(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 121>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_iaabcn_d81b83cb_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def scalar_iaabcn(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 103>\n        // tid = wp.tid()                                                                         <L 104>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 105>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        wp::array_store(var_out, var_0, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_iaabcn_d81b83cb_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out,\n    wp::float32 adj_scale,\n    wp::float32 adj_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def scalar_iaabcn(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 103>\n        // tid = wp.tid()                                                                         <L 104>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 105>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        // wp::array_store(var_out, var_0, var_4);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_4, adj_out, adj_0, adj_4);\n        wp::adj_add(var_2, var_offset, adj_2, adj_offset, adj_4);\n        wp::adj_add(var_3, var_scale, adj_1, adj_scale, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: out[tid] = x[tid] + scale + offset                                                <L 105>\n        // adj: tid = wp.tid()                                                                    <L 104>\n        // adj: def scalar_iaabcn(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):  <L 103>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_vxxkar_d3a35ca6_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 7.38;\n        const wp::float32 var_5 = -7.38;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.61;\n        const wp::float32 var_10 = -3.61;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // forward\n        // def multicond_vxxkar(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 92>\n        // tid = wp.tid()                                                                         <L 93>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 94>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -7.38:                                                                        <L 95>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 96>\n            var_8 = wp::mul(var_2, var_7);\n            wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.61:                                                                  <L 97>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 98>\n                var_13 = wp::mul(var_2, var_12);\n                wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 100>\n                var_15 = wp::mul(var_2, var_14);\n                wp::array_store(var_out, var_0, var_15);\n            }\n        }\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_vxxkar_d3a35ca6_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 7.38;\n        const wp::float32 var_5 = -7.38;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.61;\n        const wp::float32 var_10 = -3.61;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        bool adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        bool adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::float32 adj_13 = {};\n        wp::float32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        //---------\n        // forward\n        // def multicond_vxxkar(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 92>\n        // tid = wp.tid()                                                                         <L 93>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 94>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -7.38:                                                                        <L 95>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 96>\n            var_8 = wp::mul(var_2, var_7);\n            // wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.61:                                                                  <L 97>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 98>\n                var_13 = wp::mul(var_2, var_12);\n                // wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 100>\n                var_15 = wp::mul(var_2, var_14);\n                // wp::array_store(var_out, var_0, var_15);\n            }\n        }\n        //---------\n        // reverse\n        if (!var_6) {\n            if (!var_11) {\n                wp::adj_array_store(var_out, var_0, var_15, adj_out, adj_0, adj_15);\n                wp::adj_mul(var_2, var_14, adj_2, adj_14, adj_15);\n                // adj: out[tid] = val * 2.0                                                      <L 100>\n            }\n            if (var_11) {\n                wp::adj_array_store(var_out, var_0, var_13, adj_out, adj_0, adj_13);\n                wp::adj_mul(var_2, var_12, adj_2, adj_12, adj_13);\n                // adj: out[tid] = val * 1.0                                                      <L 98>\n            }\n            // adj: elif val < -3.61:                                                             <L 97>\n        }\n        if (var_6) {\n            wp::adj_array_store(var_out, var_0, var_8, adj_out, adj_0, adj_8);\n            wp::adj_mul(var_2, var_7, adj_2, adj_7, adj_8);\n            // adj: out[tid] = val * 0.5                                                          <L 96>\n        }\n        // adj: if val < -7.38:                                                                   <L 95>\n        wp::adj_copy(var_3, adj_1, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = x[tid]                                                                      <L 94>\n        // adj: tid = wp.tid()                                                                    <L 93>\n        // adj: def multicond_vxxkar(x: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 92>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_nevexy_dcb4523e_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        //---------\n        // forward\n        // def loop_nevexy(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 113>\n        // tid = wp.tid()                                                                         <L 114>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 115>\n        var_2 = wp::float(var_1);\n        // for i in range(2):                                                                     <L 116>\n        // acc = acc - arr[tid] * float(i + 1)                                                    <L 117>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::sub(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::sub(var_10, var_16);\n        // out[tid] = acc                                                                         <L 118>\n        wp::array_store(var_out, var_0, var_18);\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_nevexy_dcb4523e_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_arr,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::int32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::int32 adj_5 = {};\n        wp::int32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        wp::int32 adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::int32 adj_13 = {};\n        wp::int32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        wp::float32 adj_16 = {};\n        wp::float32 adj_17 = {};\n        wp::float32 adj_18 = {};\n        //---------\n        // forward\n        // def loop_nevexy(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 113>\n        // tid = wp.tid()                                                                         <L 114>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 115>\n        var_2 = wp::float(var_1);\n        // for i in range(2):                                                                     <L 116>\n        // acc = acc - arr[tid] * float(i + 1)                                                    <L 117>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::sub(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::sub(var_10, var_16);\n        // out[tid] = acc                                                                         <L 118>\n        // wp::array_store(var_out, var_0, var_18);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_18, adj_out, adj_0, adj_18);\n        // adj: out[tid] = acc                                                                    <L 118>\n        wp::adj_sub(var_10, var_16, adj_10, adj_16, adj_18);\n        wp::adj_mul(var_17, var_15, adj_12, adj_15, adj_16);\n        wp::adj_float(var_14, adj_14, adj_15);\n        wp::adj_add(var_11, var_13, adj_11, adj_13, adj_14);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_12);\n        wp::adj_sub(var_2, var_8, adj_2, adj_8, adj_10);\n        wp::adj_mul(var_9, var_7, adj_4, adj_7, adj_8);\n        wp::adj_float(var_6, adj_6, adj_7);\n        wp::adj_add(var_3, var_5, adj_3, adj_5, adj_6);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_4);\n        // adj: acc = acc - arr[tid] * float(i + 1)                                               <L 117>\n        // adj: for i in range(2):                                                                <L 116>\n        wp::adj_float(var_1, adj_1, adj_2);\n        // adj: acc = float(0.0)                                                                  <L 115>\n        // adj: tid = wp.tid()                                                                    <L 114>\n        // adj: def loop_nevexy(arr: wp.array(dtype=float), out: wp.array(dtype=float)):          <L 113>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_pprbst_b1f5ef05_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        //---------\n        // forward\n        // def loop_pprbst(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 127>\n        // tid = wp.tid()                                                                         <L 128>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 129>\n        var_2 = wp::float(var_1);\n        // for i in range(2):                                                                     <L 130>\n        // acc = acc + arr[tid] * float(i + 1)                                                    <L 131>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::add(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::add(var_10, var_16);\n        // out[tid] = acc                                                                         <L 132>\n        wp::array_store(var_out, var_0, var_18);\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_pprbst_b1f5ef05_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_arr,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::int32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::int32 adj_5 = {};\n        wp::int32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        wp::int32 adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::int32 adj_13 = {};\n        wp::int32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        wp::float32 adj_16 = {};\n        wp::float32 adj_17 = {};\n        wp::float32 adj_18 = {};\n        //---------\n        // forward\n        // def loop_pprbst(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 127>\n        // tid = wp.tid()                                                                         <L 128>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 129>\n        var_2 = wp::float(var_1);\n        // for i in range(2):                                                                     <L 130>\n        // acc = acc + arr[tid] * float(i + 1)                                                    <L 131>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::add(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::add(var_10, var_16);\n        // out[tid] = acc                                                                         <L 132>\n        // wp::array_store(var_out, var_0, var_18);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_18, adj_out, adj_0, adj_18);\n        // adj: out[tid] = acc                                                                    <L 132>\n        wp::adj_add(var_10, var_16, adj_10, adj_16, adj_18);\n        wp::adj_mul(var_17, var_15, adj_12, adj_15, adj_16);\n        wp::adj_float(var_14, adj_14, adj_15);\n        wp::adj_add(var_11, var_13, adj_11, adj_13, adj_14);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_12);\n        wp::adj_add(var_2, var_8, adj_2, adj_8, adj_10);\n        wp::adj_mul(var_9, var_7, adj_4, adj_7, adj_8);\n        wp::adj_float(var_6, adj_6, adj_7);\n        wp::adj_add(var_3, var_5, adj_3, adj_5, adj_6);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_4);\n        // adj: acc = acc + arr[tid] * float(i + 1)                                               <L 131>\n        // adj: for i in range(2):                                                                <L 130>\n        wp::adj_float(var_1, adj_1, adj_2);\n        // adj: acc = float(0.0)                                                                  <L 129>\n        // adj: tid = wp.tid()                                                                    <L 128>\n        // adj: def loop_pprbst(arr: wp.array(dtype=float), out: wp.array(dtype=float)):          <L 127>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_qkuafk_6ae99a79_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 7.67;\n        const wp::float32 var_2 = -7.67;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32>* var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32> var_8;\n        wp::vec_t<3, wp::float32>* var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        wp::vec_t<3, wp::float32> var_12;\n        //---------\n        // forward\n        // def vec_qkuafk(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 140>\n        // tid = wp.tid()                                                                         <L 141>\n        var_0 = builtin_tid1d();\n        // dt = -7.67                                                                             <L 142>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 143>\n        var_3 = wp::address(var_vel, var_0);\n        var_4 = wp::address(var_acc, var_0);\n        var_6 = wp::load(var_4);\n        var_5 = wp::mul(var_6, var_2);\n        var_8 = wp::load(var_3);\n        var_7 = wp::add(var_8, var_5);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 144>\n        var_9 = wp::address(var_pos, var_0);\n        var_10 = wp::mul(var_7, var_2);\n        var_12 = wp::load(var_9);\n        var_11 = wp::add(var_12, var_10);\n        wp::array_store(var_pos, var_0, var_11);\n        // vel[tid] = new_vel                                                                     <L 145>\n        wp::array_store(var_vel, var_0, var_7);\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_qkuafk_6ae99a79_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 7.67;\n        const wp::float32 var_2 = -7.67;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32>* var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32> var_8;\n        wp::vec_t<3, wp::float32>* var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        wp::vec_t<3, wp::float32> var_12;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::vec_t<3, wp::float32> adj_3 = {};\n        wp::vec_t<3, wp::float32> adj_4 = {};\n        wp::vec_t<3, wp::float32> adj_5 = {};\n        wp::vec_t<3, wp::float32> adj_6 = {};\n        wp::vec_t<3, wp::float32> adj_7 = {};\n        wp::vec_t<3, wp::float32> adj_8 = {};\n        wp::vec_t<3, wp::float32> adj_9 = {};\n        wp::vec_t<3, wp::float32> adj_10 = {};\n        wp::vec_t<3, wp::float32> adj_11 = {};\n        wp::vec_t<3, wp::float32> adj_12 = {};\n        //---------\n        // forward\n        // def vec_qkuafk(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 140>\n        // tid = wp.tid()                                                                         <L 141>\n        var_0 = builtin_tid1d();\n        // dt = -7.67                                                                             <L 142>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 143>\n        var_3 = wp::address(var_vel, var_0);\n        var_4 = wp::address(var_acc, var_0);\n        var_6 = wp::load(var_4);\n        var_5 = wp::mul(var_6, var_2);\n        var_8 = wp::load(var_3);\n        var_7 = wp::add(var_8, var_5);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 144>\n        var_9 = wp::address(var_pos, var_0);\n        var_10 = wp::mul(var_7, var_2);\n        var_12 = wp::load(var_9);\n        var_11 = wp::add(var_12, var_10);\n        // wp::array_store(var_pos, var_0, var_11);\n        // vel[tid] = new_vel                                                                     <L 145>\n        // wp::array_store(var_vel, var_0, var_7);\n        //---------\n        // reverse\n        wp::adj_array_store(var_vel, var_0, var_7, adj_vel, adj_0, adj_7);\n        // adj: vel[tid] = new_vel                                                                <L 145>\n        wp::adj_array_store(var_pos, var_0, var_11, adj_pos, adj_0, adj_11);\n        wp::adj_add(var_12, var_10, adj_9, adj_10, adj_11);\n        wp::adj_mul(var_7, var_2, adj_7, adj_2, adj_10);\n        wp::adj_address(var_pos, var_0, adj_pos, adj_0, adj_9);\n        // adj: pos[tid] = pos[tid] + new_vel * dt                                                <L 144>\n        wp::adj_add(var_8, var_5, adj_3, adj_5, adj_7);\n        wp::adj_mul(var_6, var_2, adj_4, adj_2, adj_5);\n        wp::adj_address(var_acc, var_0, adj_acc, adj_0, adj_4);\n        wp::adj_address(var_vel, var_0, adj_vel, adj_0, adj_3);\n        // adj: new_vel = vel[tid] + acc[tid] * dt                                                <L 143>\n        // adj: dt = -7.67                                                                        <L 142>\n        // adj: tid = wp.tid()                                                                    <L 141>\n        // adj: def vec_qkuafk(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):  <L 140>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_dkuqwo_f70c7d6d_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 5.25;\n        const wp::float32 var_2 = -5.25;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32>* var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32> var_8;\n        wp::vec_t<3, wp::float32>* var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        wp::vec_t<3, wp::float32> var_12;\n        //---------\n        // forward\n        // def vec_dkuqwo(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 60>\n        // tid = wp.tid()                                                                         <L 61>\n        var_0 = builtin_tid1d();\n        // dt = -5.25                                                                             <L 62>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 63>\n        var_3 = wp::address(var_vel, var_0);\n        var_4 = wp::address(var_acc, var_0);\n        var_6 = wp::load(var_4);\n        var_5 = wp::mul(var_6, var_2);\n        var_8 = wp::load(var_3);\n        var_7 = wp::add(var_8, var_5);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 64>\n        var_9 = wp::address(var_pos, var_0);\n        var_10 = wp::mul(var_7, var_2);\n        var_12 = wp::load(var_9);\n        var_11 = wp::add(var_12, var_10);\n        wp::array_store(var_pos, var_0, var_11);\n        // vel[tid] = new_vel                                                                     <L 65>\n        wp::array_store(var_vel, var_0, var_7);\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_dkuqwo_f70c7d6d_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 5.25;\n        const wp::float32 var_2 = -5.25;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32>* var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32> var_8;\n        wp::vec_t<3, wp::float32>* var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        wp::vec_t<3, wp::float32> var_12;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::vec_t<3, wp::float32> adj_3 = {};\n        wp::vec_t<3, wp::float32> adj_4 = {};\n        wp::vec_t<3, wp::float32> adj_5 = {};\n        wp::vec_t<3, wp::float32> adj_6 = {};\n        wp::vec_t<3, wp::float32> adj_7 = {};\n        wp::vec_t<3, wp::float32> adj_8 = {};\n        wp::vec_t<3, wp::float32> adj_9 = {};\n        wp::vec_t<3, wp::float32> adj_10 = {};\n        wp::vec_t<3, wp::float32> adj_11 = {};\n        wp::vec_t<3, wp::float32> adj_12 = {};\n        //---------\n        // forward\n        // def vec_dkuqwo(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 60>\n        // tid = wp.tid()                                                                         <L 61>\n        var_0 = builtin_tid1d();\n        // dt = -5.25                                                                             <L 62>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 63>\n        var_3 = wp::address(var_vel, var_0);\n        var_4 = wp::address(var_acc, var_0);\n        var_6 = wp::load(var_4);\n        var_5 = wp::mul(var_6, var_2);\n        var_8 = wp::load(var_3);\n        var_7 = wp::add(var_8, var_5);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 64>\n        var_9 = wp::address(var_pos, var_0);\n        var_10 = wp::mul(var_7, var_2);\n        var_12 = wp::load(var_9);\n        var_11 = wp::add(var_12, var_10);\n        // wp::array_store(var_pos, var_0, var_11);\n        // vel[tid] = new_vel                                                                     <L 65>\n        // wp::array_store(var_vel, var_0, var_7);\n        //---------\n        // reverse\n        wp::adj_array_store(var_vel, var_0, var_7, adj_vel, adj_0, adj_7);\n        // adj: vel[tid] = new_vel                                                                <L 65>\n        wp::adj_array_store(var_pos, var_0, var_11, adj_pos, adj_0, adj_11);\n        wp::adj_add(var_12, var_10, adj_9, adj_10, adj_11);\n        wp::adj_mul(var_7, var_2, adj_7, adj_2, adj_10);\n        wp::adj_address(var_pos, var_0, adj_pos, adj_0, adj_9);\n        // adj: pos[tid] = pos[tid] + new_vel * dt                                                <L 64>\n        wp::adj_add(var_8, var_5, adj_3, adj_5, adj_7);\n        wp::adj_mul(var_6, var_2, adj_4, adj_2, adj_5);\n        wp::adj_address(var_acc, var_0, adj_acc, adj_0, adj_4);\n        wp::adj_address(var_vel, var_0, adj_vel, adj_0, adj_3);\n        // adj: new_vel = vel[tid] + acc[tid] * dt                                                <L 63>\n        // adj: dt = -5.25                                                                        <L 62>\n        // adj: tid = wp.tid()                                                                    <L 61>\n        // adj: def vec_dkuqwo(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):  <L 60>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_tduvog_6a3efa4a_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 8.31;\n        wp::vec_t<3, wp::float32>* var_2;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32> var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32>* var_8;\n        wp::vec_t<3, wp::float32> var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        //---------\n        // forward\n        // def vec_tduvog(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 79>\n        // tid = wp.tid()                                                                         <L 80>\n        var_0 = builtin_tid1d();\n        // dt = 8.31                                                                              <L 81>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 82>\n        var_2 = wp::address(var_vel, var_0);\n        var_3 = wp::address(var_acc, var_0);\n        var_5 = wp::load(var_3);\n        var_4 = wp::mul(var_5, var_1);\n        var_7 = wp::load(var_2);\n        var_6 = wp::add(var_7, var_4);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 83>\n        var_8 = wp::address(var_pos, var_0);\n        var_9 = wp::mul(var_6, var_1);\n        var_11 = wp::load(var_8);\n        var_10 = wp::add(var_11, var_9);\n        wp::array_store(var_pos, var_0, var_10);\n        // vel[tid] = new_vel                                                                     <L 84>\n        wp::array_store(var_vel, var_0, var_6);\n    }\n}\n\n\n\nextern \"C\" __global__ void vec_tduvog_6a3efa4a_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> var_acc,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_pos,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_vel,\n    wp::array_t<wp::vec_t<3, wp::float32>> adj_acc)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 8.31;\n        wp::vec_t<3, wp::float32>* var_2;\n        wp::vec_t<3, wp::float32>* var_3;\n        wp::vec_t<3, wp::float32> var_4;\n        wp::vec_t<3, wp::float32> var_5;\n        wp::vec_t<3, wp::float32> var_6;\n        wp::vec_t<3, wp::float32> var_7;\n        wp::vec_t<3, wp::float32>* var_8;\n        wp::vec_t<3, wp::float32> var_9;\n        wp::vec_t<3, wp::float32> var_10;\n        wp::vec_t<3, wp::float32> var_11;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::vec_t<3, wp::float32> adj_2 = {};\n        wp::vec_t<3, wp::float32> adj_3 = {};\n        wp::vec_t<3, wp::float32> adj_4 = {};\n        wp::vec_t<3, wp::float32> adj_5 = {};\n        wp::vec_t<3, wp::float32> adj_6 = {};\n        wp::vec_t<3, wp::float32> adj_7 = {};\n        wp::vec_t<3, wp::float32> adj_8 = {};\n        wp::vec_t<3, wp::float32> adj_9 = {};\n        wp::vec_t<3, wp::float32> adj_10 = {};\n        wp::vec_t<3, wp::float32> adj_11 = {};\n        //---------\n        // forward\n        // def vec_tduvog(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):       <L 79>\n        // tid = wp.tid()                                                                         <L 80>\n        var_0 = builtin_tid1d();\n        // dt = 8.31                                                                              <L 81>\n        // new_vel = vel[tid] + acc[tid] * dt                                                     <L 82>\n        var_2 = wp::address(var_vel, var_0);\n        var_3 = wp::address(var_acc, var_0);\n        var_5 = wp::load(var_3);\n        var_4 = wp::mul(var_5, var_1);\n        var_7 = wp::load(var_2);\n        var_6 = wp::add(var_7, var_4);\n        // pos[tid] = pos[tid] + new_vel * dt                                                     <L 83>\n        var_8 = wp::address(var_pos, var_0);\n        var_9 = wp::mul(var_6, var_1);\n        var_11 = wp::load(var_8);\n        var_10 = wp::add(var_11, var_9);\n        // wp::array_store(var_pos, var_0, var_10);\n        // vel[tid] = new_vel                                                                     <L 84>\n        // wp::array_store(var_vel, var_0, var_6);\n        //---------\n        // reverse\n        wp::adj_array_store(var_vel, var_0, var_6, adj_vel, adj_0, adj_6);\n        // adj: vel[tid] = new_vel                                                                <L 84>\n        wp::adj_array_store(var_pos, var_0, var_10, adj_pos, adj_0, adj_10);\n        wp::adj_add(var_11, var_9, adj_8, adj_9, adj_10);\n        wp::adj_mul(var_6, var_1, adj_6, adj_1, adj_9);\n        wp::adj_address(var_pos, var_0, adj_pos, adj_0, adj_8);\n        // adj: pos[tid] = pos[tid] + new_vel * dt                                                <L 83>\n        wp::adj_add(var_7, var_4, adj_2, adj_4, adj_6);\n        wp::adj_mul(var_5, var_1, adj_3, adj_1, adj_4);\n        wp::adj_address(var_acc, var_0, adj_acc, adj_0, adj_3);\n        wp::adj_address(var_vel, var_0, adj_vel, adj_0, adj_2);\n        // adj: new_vel = vel[tid] + acc[tid] * dt                                                <L 82>\n        // adj: dt = 8.31                                                                         <L 81>\n        // adj: tid = wp.tid()                                                                    <L 80>\n        // adj: def vec_tduvog(pos: wp.array(dtype=wp.vec3), vel: wp.array(dtype=wp.vec3), acc: wp.array(dtype=wp.vec3)):  <L 79>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void math_iqjhbi_89968146_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        const wp::float32 var_2 = 3.14;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // forward\n        // def math_iqjhbi(x: wp.array(dtype=float), out: wp.array(dtype=float)):                 <L 30>\n        // tid = wp.tid()                                                                         <L 31>\n        var_0 = builtin_tid1d();\n        // val = wp.cos(x[tid] * 3.14)                                                            <L 32>\n        var_1 = wp::address(var_x, var_0);\n        var_4 = wp::load(var_1);\n        var_3 = wp::mul(var_4, var_2);\n        var_5 = wp::cos(var_3);\n        // out[tid] = wp.sin(val)                                                                 <L 33>\n        var_6 = wp::sin(var_5);\n        wp::array_store(var_out, var_0, var_6);\n    }\n}\n\n\n\nextern \"C\" __global__ void math_iqjhbi_89968146_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        const wp::float32 var_2 = 3.14;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        wp::float32 adj_6 = {};\n        //---------\n        // forward\n        // def math_iqjhbi(x: wp.array(dtype=float), out: wp.array(dtype=float)):                 <L 30>\n        // tid = wp.tid()                                                                         <L 31>\n        var_0 = builtin_tid1d();\n        // val = wp.cos(x[tid] * 3.14)                                                            <L 32>\n        var_1 = wp::address(var_x, var_0);\n        var_4 = wp::load(var_1);\n        var_3 = wp::mul(var_4, var_2);\n        var_5 = wp::cos(var_3);\n        // out[tid] = wp.sin(val)                                                                 <L 33>\n        var_6 = wp::sin(var_5);\n        // wp::array_store(var_out, var_0, var_6);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_6, adj_out, adj_0, adj_6);\n        wp::adj_sin(var_5, adj_5, adj_6);\n        // adj: out[tid] = wp.sin(val)                                                            <L 33>\n        wp::adj_cos(var_3, adj_3, adj_5);\n        wp::adj_mul(var_4, var_2, adj_1, adj_2, adj_3);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = wp.cos(x[tid] * 3.14)                                                       <L 32>\n        // adj: tid = wp.tid()                                                                    <L 31>\n        // adj: def math_iqjhbi(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 30>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_pxhhtr_b58cf707_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def scalar_pxhhtr(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 87>\n        // tid = wp.tid()                                                                         <L 88>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 89>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        wp::array_store(var_out, var_0, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_pxhhtr_b58cf707_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out,\n    wp::float32 adj_scale,\n    wp::float32 adj_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def scalar_pxhhtr(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 87>\n        // tid = wp.tid()                                                                         <L 88>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] + scale + offset                                                     <L 89>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::add(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        // wp::array_store(var_out, var_0, var_4);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_4, adj_out, adj_0, adj_4);\n        wp::adj_add(var_2, var_offset, adj_2, adj_offset, adj_4);\n        wp::adj_add(var_3, var_scale, adj_1, adj_scale, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: out[tid] = x[tid] + scale + offset                                                <L 89>\n        // adj: tid = wp.tid()                                                                    <L 88>\n        // adj: def scalar_pxhhtr(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):  <L 87>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_uahjbg_4a66b846_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 8.83;\n        const wp::float32 var_5 = -8.83;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.29;\n        const wp::float32 var_10 = -3.29;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // forward\n        // def multicond_uahjbg(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 68>\n        // tid = wp.tid()                                                                         <L 69>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 70>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -8.83:                                                                        <L 71>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 72>\n            var_8 = wp::mul(var_2, var_7);\n            wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.29:                                                                  <L 73>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 74>\n                var_13 = wp::mul(var_2, var_12);\n                wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 76>\n                var_15 = wp::mul(var_2, var_14);\n                wp::array_store(var_out, var_0, var_15);\n            }\n        }\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_uahjbg_4a66b846_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 8.83;\n        const wp::float32 var_5 = -8.83;\n        bool var_6;\n        const wp::float32 var_7 = 0.5;\n        wp::float32 var_8;\n        const wp::float32 var_9 = 3.29;\n        const wp::float32 var_10 = -3.29;\n        bool var_11;\n        const wp::float32 var_12 = 1.0;\n        wp::float32 var_13;\n        const wp::float32 var_14 = 2.0;\n        wp::float32 var_15;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        bool adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        bool adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::float32 adj_13 = {};\n        wp::float32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        //---------\n        // forward\n        // def multicond_uahjbg(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 68>\n        // tid = wp.tid()                                                                         <L 69>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 70>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < -8.83:                                                                        <L 71>\n        var_6 = (var_2 < var_5);\n        if (var_6) {\n            // out[tid] = val * 0.5                                                               <L 72>\n            var_8 = wp::mul(var_2, var_7);\n            // wp::array_store(var_out, var_0, var_8);\n        }\n        if (!var_6) {\n            // elif val < -3.29:                                                                  <L 73>\n            var_11 = (var_2 < var_10);\n            if (var_11) {\n                // out[tid] = val * 1.0                                                           <L 74>\n                var_13 = wp::mul(var_2, var_12);\n                // wp::array_store(var_out, var_0, var_13);\n            }\n            if (!var_11) {\n                // out[tid] = val * 2.0                                                           <L 76>\n                var_15 = wp::mul(var_2, var_14);\n                // wp::array_store(var_out, var_0, var_15);\n            }\n        }\n        //---------\n        // reverse\n        if (!var_6) {\n            if (!var_11) {\n                wp::adj_array_store(var_out, var_0, var_15, adj_out, adj_0, adj_15);\n                wp::adj_mul(var_2, var_14, adj_2, adj_14, adj_15);\n                // adj: out[tid] = val * 2.0                                                      <L 76>\n            }\n            if (var_11) {\n                wp::adj_array_store(var_out, var_0, var_13, adj_out, adj_0, adj_13);\n                wp::adj_mul(var_2, var_12, adj_2, adj_12, adj_13);\n                // adj: out[tid] = val * 1.0                                                      <L 74>\n            }\n            // adj: elif val < -3.29:                                                             <L 73>\n        }\n        if (var_6) {\n            wp::adj_array_store(var_out, var_0, var_8, adj_out, adj_0, adj_8);\n            wp::adj_mul(var_2, var_7, adj_2, adj_7, adj_8);\n            // adj: out[tid] = val * 0.5                                                          <L 72>\n        }\n        // adj: if val < -8.83:                                                                   <L 71>\n        wp::adj_copy(var_3, adj_1, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = x[tid]                                                                      <L 70>\n        // adj: tid = wp.tid()                                                                    <L 69>\n        // adj: def multicond_uahjbg(x: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 68>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_kutipb_77400193_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def scalar_kutipb(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 25>\n        // tid = wp.tid()                                                                         <L 26>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] * scale + offset                                                     <L 27>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::mul(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        wp::array_store(var_out, var_0, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_kutipb_77400193_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out,\n    wp::float32 adj_scale,\n    wp::float32 adj_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def scalar_kutipb(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 25>\n        // tid = wp.tid()                                                                         <L 26>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] * scale + offset                                                     <L 27>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::mul(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        // wp::array_store(var_out, var_0, var_4);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_4, adj_out, adj_0, adj_4);\n        wp::adj_add(var_2, var_offset, adj_2, adj_offset, adj_4);\n        wp::adj_mul(var_3, var_scale, adj_1, adj_scale, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: out[tid] = x[tid] * scale + offset                                                <L 27>\n        // adj: tid = wp.tid()                                                                    <L 26>\n        // adj: def scalar_kutipb(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):  <L 25>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void arith_weidvd_1b4789cf_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_a,\n    wp::array_t<wp::float32> var_b,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        const wp::float32 var_6 = 2.72;\n        const wp::float32 var_7 = -2.72;\n        wp::float32 var_8;\n        //---------\n        // forward\n        // def arith_weidvd(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 135>\n        // tid = wp.tid()                                                                         <L 136>\n        var_0 = builtin_tid1d();\n        // out[tid] = (a[tid] - b[tid]) + -2.72                                                   <L 137>\n        var_1 = wp::address(var_a, var_0);\n        var_2 = wp::address(var_b, var_0);\n        var_4 = wp::load(var_1);\n        var_5 = wp::load(var_2);\n        var_3 = wp::sub(var_4, var_5);\n        var_8 = wp::add(var_3, var_7);\n        wp::array_store(var_out, var_0, var_8);\n    }\n}\n\n\n\nextern \"C\" __global__ void arith_weidvd_1b4789cf_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_a,\n    wp::array_t<wp::float32> var_b,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_a,\n    wp::array_t<wp::float32> adj_b,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        const wp::float32 var_6 = 2.72;\n        const wp::float32 var_7 = -2.72;\n        wp::float32 var_8;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        wp::float32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        //---------\n        // forward\n        // def arith_weidvd(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 135>\n        // tid = wp.tid()                                                                         <L 136>\n        var_0 = builtin_tid1d();\n        // out[tid] = (a[tid] - b[tid]) + -2.72                                                   <L 137>\n        var_1 = wp::address(var_a, var_0);\n        var_2 = wp::address(var_b, var_0);\n        var_4 = wp::load(var_1);\n        var_5 = wp::load(var_2);\n        var_3 = wp::sub(var_4, var_5);\n        var_8 = wp::add(var_3, var_7);\n        // wp::array_store(var_out, var_0, var_8);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_8, adj_out, adj_0, adj_8);\n        wp::adj_add(var_3, var_7, adj_3, adj_7, adj_8);\n        wp::adj_sub(var_4, var_5, adj_1, adj_2, adj_3);\n        wp::adj_address(var_b, var_0, adj_b, adj_0, adj_2);\n        wp::adj_address(var_a, var_0, adj_a, adj_0, adj_1);\n        // adj: out[tid] = (a[tid] - b[tid]) + -2.72                                              <L 137>\n        // adj: tid = wp.tid()                                                                    <L 136>\n        // adj: def arith_weidvd(a: wp.array(dtype=float), b: wp.array(dtype=float), out: wp.array(dtype=float)):  <L 135>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void atomic_ztqqfc_ca16ddc9_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_values,\n    wp::array_t<wp::float32> var_result)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::int32 var_1 = 0;\n        wp::float32* var_2;\n        const wp::float32 var_3 = 4.02;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // forward\n        // def atomic_ztqqfc(values: wp.array(dtype=float), result: wp.array(dtype=float)):       <L 20>\n        // tid = wp.tid()                                                                         <L 21>\n        var_0 = builtin_tid1d();\n        // wp.atomic_add(result, 0, values[tid] * 4.02)                                           <L 22>\n        var_2 = wp::address(var_values, var_0);\n        var_5 = wp::load(var_2);\n        var_4 = wp::mul(var_5, var_3);\n        var_6 = wp::atomic_add(var_result, var_1, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void atomic_ztqqfc_ca16ddc9_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_values,\n    wp::array_t<wp::float32> var_result,\n    wp::array_t<wp::float32> adj_values,\n    wp::array_t<wp::float32> adj_result)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::int32 var_1 = 0;\n        wp::float32* var_2;\n        const wp::float32 var_3 = 4.02;\n        wp::float32 var_4;\n        wp::float32 var_5;\n        wp::float32 var_6;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::int32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::float32 adj_5 = {};\n        wp::float32 adj_6 = {};\n        //---------\n        // forward\n        // def atomic_ztqqfc(values: wp.array(dtype=float), result: wp.array(dtype=float)):       <L 20>\n        // tid = wp.tid()                                                                         <L 21>\n        var_0 = builtin_tid1d();\n        // wp.atomic_add(result, 0, values[tid] * 4.02)                                           <L 22>\n        var_2 = wp::address(var_values, var_0);\n        var_5 = wp::load(var_2);\n        var_4 = wp::mul(var_5, var_3);\n        // var_6 = wp::atomic_add(var_result, var_1, var_4);\n        //---------\n        // reverse\n        wp::adj_atomic_add(var_result, var_1, var_4, adj_result, adj_1, adj_4, adj_6);\n        wp::adj_mul(var_5, var_3, adj_2, adj_3, adj_4);\n        wp::adj_address(var_values, var_0, adj_values, adj_0, adj_2);\n        // adj: wp.atomic_add(result, 0, values[tid] * 4.02)                                      <L 22>\n        // adj: tid = wp.tid()                                                                    <L 21>\n        // adj: def atomic_ztqqfc(values: wp.array(dtype=float), result: wp.array(dtype=float)):  <L 20>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_ronhym_3a654de8_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def scalar_ronhym(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 108>\n        // tid = wp.tid()                                                                         <L 109>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] - scale + offset                                                     <L 110>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::sub(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        wp::array_store(var_out, var_0, var_4);\n    }\n}\n\n\n\nextern \"C\" __global__ void scalar_ronhym_3a654de8_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::float32 var_scale,\n    wp::float32 var_offset,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out,\n    wp::float32 adj_scale,\n    wp::float32 adj_offset)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def scalar_ronhym(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):       <L 108>\n        // tid = wp.tid()                                                                         <L 109>\n        var_0 = builtin_tid1d();\n        // out[tid] = x[tid] - scale + offset                                                     <L 110>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::sub(var_3, var_scale);\n        var_4 = wp::add(var_2, var_offset);\n        // wp::array_store(var_out, var_0, var_4);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_4, adj_out, adj_0, adj_4);\n        wp::adj_add(var_2, var_offset, adj_2, adj_offset, adj_4);\n        wp::adj_sub(var_3, var_scale, adj_1, adj_scale, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: out[tid] = x[tid] - scale + offset                                                <L 110>\n        // adj: tid = wp.tid()                                                                    <L 109>\n        // adj: def scalar_ronhym(x: wp.array(dtype=float), out: wp.array(dtype=float), scale: float, offset: float):  <L 108>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_zzyhsz_6bdad60f_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 1.43;\n        bool var_5;\n        const wp::float32 var_6 = 0.5;\n        wp::float32 var_7;\n        const wp::float32 var_8 = 7.76;\n        bool var_9;\n        const wp::float32 var_10 = 1.0;\n        wp::float32 var_11;\n        const wp::float32 var_12 = 2.0;\n        wp::float32 var_13;\n        //---------\n        // forward\n        // def multicond_zzyhsz(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 49>\n        // tid = wp.tid()                                                                         <L 50>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 51>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < 1.43:                                                                         <L 52>\n        var_5 = (var_2 < var_4);\n        if (var_5) {\n            // out[tid] = val * 0.5                                                               <L 53>\n            var_7 = wp::mul(var_2, var_6);\n            wp::array_store(var_out, var_0, var_7);\n        }\n        if (!var_5) {\n            // elif val < 7.76:                                                                   <L 54>\n            var_9 = (var_2 < var_8);\n            if (var_9) {\n                // out[tid] = val * 1.0                                                           <L 55>\n                var_11 = wp::mul(var_2, var_10);\n                wp::array_store(var_out, var_0, var_11);\n            }\n            if (!var_9) {\n                // out[tid] = val * 2.0                                                           <L 57>\n                var_13 = wp::mul(var_2, var_12);\n                wp::array_store(var_out, var_0, var_13);\n            }\n        }\n    }\n}\n\n\n\nextern \"C\" __global__ void multicond_zzyhsz_6bdad60f_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_x,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_x,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        wp::float32* var_1;\n        wp::float32 var_2;\n        wp::float32 var_3;\n        const wp::float32 var_4 = 1.43;\n        bool var_5;\n        const wp::float32 var_6 = 0.5;\n        wp::float32 var_7;\n        const wp::float32 var_8 = 7.76;\n        bool var_9;\n        const wp::float32 var_10 = 1.0;\n        wp::float32 var_11;\n        const wp::float32 var_12 = 2.0;\n        wp::float32 var_13;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        bool adj_5 = {};\n        wp::float32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        bool adj_9 = {};\n        wp::float32 adj_10 = {};\n        wp::float32 adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::float32 adj_13 = {};\n        //---------\n        // forward\n        // def multicond_zzyhsz(x: wp.array(dtype=float), out: wp.array(dtype=float)):            <L 49>\n        // tid = wp.tid()                                                                         <L 50>\n        var_0 = builtin_tid1d();\n        // val = x[tid]                                                                           <L 51>\n        var_1 = wp::address(var_x, var_0);\n        var_3 = wp::load(var_1);\n        var_2 = wp::copy(var_3);\n        // if val < 1.43:                                                                         <L 52>\n        var_5 = (var_2 < var_4);\n        if (var_5) {\n            // out[tid] = val * 0.5                                                               <L 53>\n            var_7 = wp::mul(var_2, var_6);\n            // wp::array_store(var_out, var_0, var_7);\n        }\n        if (!var_5) {\n            // elif val < 7.76:                                                                   <L 54>\n            var_9 = (var_2 < var_8);\n            if (var_9) {\n                // out[tid] = val * 1.0                                                           <L 55>\n                var_11 = wp::mul(var_2, var_10);\n                // wp::array_store(var_out, var_0, var_11);\n            }\n            if (!var_9) {\n                // out[tid] = val * 2.0                                                           <L 57>\n                var_13 = wp::mul(var_2, var_12);\n                // wp::array_store(var_out, var_0, var_13);\n            }\n        }\n        //---------\n        // reverse\n        if (!var_5) {\n            if (!var_9) {\n                wp::adj_array_store(var_out, var_0, var_13, adj_out, adj_0, adj_13);\n                wp::adj_mul(var_2, var_12, adj_2, adj_12, adj_13);\n                // adj: out[tid] = val * 2.0                                                      <L 57>\n            }\n            if (var_9) {\n                wp::adj_array_store(var_out, var_0, var_11, adj_out, adj_0, adj_11);\n                wp::adj_mul(var_2, var_10, adj_2, adj_10, adj_11);\n                // adj: out[tid] = val * 1.0                                                      <L 55>\n            }\n            // adj: elif val < 7.76:                                                              <L 54>\n        }\n        if (var_5) {\n            wp::adj_array_store(var_out, var_0, var_7, adj_out, adj_0, adj_7);\n            wp::adj_mul(var_2, var_6, adj_2, adj_6, adj_7);\n            // adj: out[tid] = val * 0.5                                                          <L 53>\n        }\n        // adj: if val < 1.43:                                                                    <L 52>\n        wp::adj_copy(var_3, adj_1, adj_2);\n        wp::adj_address(var_x, var_0, adj_x, adj_0, adj_1);\n        // adj: val = x[tid]                                                                      <L 51>\n        // adj: tid = wp.tid()                                                                    <L 50>\n        // adj: def multicond_zzyhsz(x: wp.array(dtype=float), out: wp.array(dtype=float)):       <L 49>\n        continue;\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_uyelzo_c89c255e_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        const wp::int32 var_19 = 2;\n        wp::float32* var_20;\n        const wp::int32 var_21 = 1;\n        wp::int32 var_22;\n        wp::float32 var_23;\n        wp::float32 var_24;\n        wp::float32 var_25;\n        wp::float32 var_26;\n        const wp::int32 var_27 = 3;\n        wp::float32* var_28;\n        const wp::int32 var_29 = 1;\n        wp::int32 var_30;\n        wp::float32 var_31;\n        wp::float32 var_32;\n        wp::float32 var_33;\n        wp::float32 var_34;\n        const wp::int32 var_35 = 4;\n        wp::float32* var_36;\n        const wp::int32 var_37 = 1;\n        wp::int32 var_38;\n        wp::float32 var_39;\n        wp::float32 var_40;\n        wp::float32 var_41;\n        wp::float32 var_42;\n        //---------\n        // forward\n        // def loop_uyelzo(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 36>\n        // tid = wp.tid()                                                                         <L 37>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 38>\n        var_2 = wp::float(var_1);\n        // for i in range(5):                                                                     <L 39>\n        // acc = acc + arr[tid] * float(i + 1)                                                    <L 40>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::add(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::add(var_10, var_16);\n        var_20 = wp::address(var_arr, var_0);\n        var_22 = wp::add(var_19, var_21);\n        var_23 = wp::float(var_22);\n        var_25 = wp::load(var_20);\n        var_24 = wp::mul(var_25, var_23);\n        var_26 = wp::add(var_18, var_24);\n        var_28 = wp::address(var_arr, var_0);\n        var_30 = wp::add(var_27, var_29);\n        var_31 = wp::float(var_30);\n        var_33 = wp::load(var_28);\n        var_32 = wp::mul(var_33, var_31);\n        var_34 = wp::add(var_26, var_32);\n        var_36 = wp::address(var_arr, var_0);\n        var_38 = wp::add(var_35, var_37);\n        var_39 = wp::float(var_38);\n        var_41 = wp::load(var_36);\n        var_40 = wp::mul(var_41, var_39);\n        var_42 = wp::add(var_34, var_40);\n        // out[tid] = acc                                                                         <L 41>\n        wp::array_store(var_out, var_0, var_42);\n    }\n}\n\n\n\nextern \"C\" __global__ void loop_uyelzo_c89c255e_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_arr,\n    wp::array_t<wp::float32> var_out,\n    wp::array_t<wp::float32> adj_arr,\n    wp::array_t<wp::float32> adj_out)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::float32 var_1 = 0.0;\n        wp::float32 var_2;\n        const wp::int32 var_3 = 0;\n        wp::float32* var_4;\n        const wp::int32 var_5 = 1;\n        wp::int32 var_6;\n        wp::float32 var_7;\n        wp::float32 var_8;\n        wp::float32 var_9;\n        wp::float32 var_10;\n        const wp::int32 var_11 = 1;\n        wp::float32* var_12;\n        const wp::int32 var_13 = 1;\n        wp::int32 var_14;\n        wp::float32 var_15;\n        wp::float32 var_16;\n        wp::float32 var_17;\n        wp::float32 var_18;\n        const wp::int32 var_19 = 2;\n        wp::float32* var_20;\n        const wp::int32 var_21 = 1;\n        wp::int32 var_22;\n        wp::float32 var_23;\n        wp::float32 var_24;\n        wp::float32 var_25;\n        wp::float32 var_26;\n        const wp::int32 var_27 = 3;\n        wp::float32* var_28;\n        const wp::int32 var_29 = 1;\n        wp::int32 var_30;\n        wp::float32 var_31;\n        wp::float32 var_32;\n        wp::float32 var_33;\n        wp::float32 var_34;\n        const wp::int32 var_35 = 4;\n        wp::float32* var_36;\n        const wp::int32 var_37 = 1;\n        wp::int32 var_38;\n        wp::float32 var_39;\n        wp::float32 var_40;\n        wp::float32 var_41;\n        wp::float32 var_42;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::float32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::int32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        wp::int32 adj_5 = {};\n        wp::int32 adj_6 = {};\n        wp::float32 adj_7 = {};\n        wp::float32 adj_8 = {};\n        wp::float32 adj_9 = {};\n        wp::float32 adj_10 = {};\n        wp::int32 adj_11 = {};\n        wp::float32 adj_12 = {};\n        wp::int32 adj_13 = {};\n        wp::int32 adj_14 = {};\n        wp::float32 adj_15 = {};\n        wp::float32 adj_16 = {};\n        wp::float32 adj_17 = {};\n        wp::float32 adj_18 = {};\n        wp::int32 adj_19 = {};\n        wp::float32 adj_20 = {};\n        wp::int32 adj_21 = {};\n        wp::int32 adj_22 = {};\n        wp::float32 adj_23 = {};\n        wp::float32 adj_24 = {};\n        wp::float32 adj_25 = {};\n        wp::float32 adj_26 = {};\n        wp::int32 adj_27 = {};\n        wp::float32 adj_28 = {};\n        wp::int32 adj_29 = {};\n        wp::int32 adj_30 = {};\n        wp::float32 adj_31 = {};\n        wp::float32 adj_32 = {};\n        wp::float32 adj_33 = {};\n        wp::float32 adj_34 = {};\n        wp::int32 adj_35 = {};\n        wp::float32 adj_36 = {};\n        wp::int32 adj_37 = {};\n        wp::int32 adj_38 = {};\n        wp::float32 adj_39 = {};\n        wp::float32 adj_40 = {};\n        wp::float32 adj_41 = {};\n        wp::float32 adj_42 = {};\n        //---------\n        // forward\n        // def loop_uyelzo(arr: wp.array(dtype=float), out: wp.array(dtype=float)):               <L 36>\n        // tid = wp.tid()                                                                         <L 37>\n        var_0 = builtin_tid1d();\n        // acc = float(0.0)                                                                       <L 38>\n        var_2 = wp::float(var_1);\n        // for i in range(5):                                                                     <L 39>\n        // acc = acc + arr[tid] * float(i + 1)                                                    <L 40>\n        var_4 = wp::address(var_arr, var_0);\n        var_6 = wp::add(var_3, var_5);\n        var_7 = wp::float(var_6);\n        var_9 = wp::load(var_4);\n        var_8 = wp::mul(var_9, var_7);\n        var_10 = wp::add(var_2, var_8);\n        var_12 = wp::address(var_arr, var_0);\n        var_14 = wp::add(var_11, var_13);\n        var_15 = wp::float(var_14);\n        var_17 = wp::load(var_12);\n        var_16 = wp::mul(var_17, var_15);\n        var_18 = wp::add(var_10, var_16);\n        var_20 = wp::address(var_arr, var_0);\n        var_22 = wp::add(var_19, var_21);\n        var_23 = wp::float(var_22);\n        var_25 = wp::load(var_20);\n        var_24 = wp::mul(var_25, var_23);\n        var_26 = wp::add(var_18, var_24);\n        var_28 = wp::address(var_arr, var_0);\n        var_30 = wp::add(var_27, var_29);\n        var_31 = wp::float(var_30);\n        var_33 = wp::load(var_28);\n        var_32 = wp::mul(var_33, var_31);\n        var_34 = wp::add(var_26, var_32);\n        var_36 = wp::address(var_arr, var_0);\n        var_38 = wp::add(var_35, var_37);\n        var_39 = wp::float(var_38);\n        var_41 = wp::load(var_36);\n        var_40 = wp::mul(var_41, var_39);\n        var_42 = wp::add(var_34, var_40);\n        // out[tid] = acc                                                                         <L 41>\n        // wp::array_store(var_out, var_0, var_42);\n        //---------\n        // reverse\n        wp::adj_array_store(var_out, var_0, var_42, adj_out, adj_0, adj_42);\n        // adj: out[tid] = acc                                                                    <L 41>\n        wp::adj_add(var_34, var_40, adj_34, adj_40, adj_42);\n        wp::adj_mul(var_41, var_39, adj_36, adj_39, adj_40);\n        wp::adj_float(var_38, adj_38, adj_39);\n        wp::adj_add(var_35, var_37, adj_35, adj_37, adj_38);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_36);\n        wp::adj_add(var_26, var_32, adj_26, adj_32, adj_34);\n        wp::adj_mul(var_33, var_31, adj_28, adj_31, adj_32);\n        wp::adj_float(var_30, adj_30, adj_31);\n        wp::adj_add(var_27, var_29, adj_27, adj_29, adj_30);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_28);\n        wp::adj_add(var_18, var_24, adj_18, adj_24, adj_26);\n        wp::adj_mul(var_25, var_23, adj_20, adj_23, adj_24);\n        wp::adj_float(var_22, adj_22, adj_23);\n        wp::adj_add(var_19, var_21, adj_19, adj_21, adj_22);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_20);\n        wp::adj_add(var_10, var_16, adj_10, adj_16, adj_18);\n        wp::adj_mul(var_17, var_15, adj_12, adj_15, adj_16);\n        wp::adj_float(var_14, adj_14, adj_15);\n        wp::adj_add(var_11, var_13, adj_11, adj_13, adj_14);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_12);\n        wp::adj_add(var_2, var_8, adj_2, adj_8, adj_10);\n        wp::adj_mul(var_9, var_7, adj_4, adj_7, adj_8);\n        wp::adj_float(var_6, adj_6, adj_7);\n        wp::adj_add(var_3, var_5, adj_3, adj_5, adj_6);\n        wp::adj_address(var_arr, var_0, adj_arr, adj_0, adj_4);\n        // adj: acc = acc + arr[tid] * float(i + 1)                                               <L 40>\n        // adj: for i in range(5):                                                                <L 39>\n        wp::adj_float(var_1, adj_1, adj_2);\n        // adj: acc = float(0.0)                                                                  <L 38>\n        // adj: tid = wp.tid()                                                                    <L 37>\n        // adj: def loop_uyelzo(arr: wp.array(dtype=float), out: wp.array(dtype=float)):          <L 36>\n        continue;\n    }\n}\n\n",
  "generated_at": "2025-12-28T22:22:04",
  "metadata": {
    "num_params": 3,
    "num_lines": 5,
    "device": "cuda"
  }
}
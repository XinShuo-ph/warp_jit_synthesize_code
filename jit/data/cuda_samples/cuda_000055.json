{
  "python_source": "@wp.kernel\ndef atom_cydtvt(values: wp.array(dtype=float), result: wp.array(dtype=float)):\n    tid = wp.tid()\n    wp.atomic_min(result, 0, values[tid])\n",
  "ir_forward": "void atom_cydtvt_9ad61039_cuda_kernel_forward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_values,\n    wp::array_t<wp::float32> var_result)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::int32 var_1 = 0;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // forward\n        // def atom_cydtvt(values: wp.array(dtype=float), result: wp.array(dtype=float)):         <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // wp.atomic_min(result, 0, values[tid])                                                  <L 6>\n        var_2 = wp::address(var_values, var_0);\n        var_4 = wp::load(var_2);\n        var_3 = wp::atomic_min(var_result, var_1, var_4);\n    }\n}",
  "metadata": {
    "kernel_name": "atom_cydtvt",
    "category": "atomic",
    "description": "Atomic min reduction",
    "device": "cuda",
    "ir_type": "cuda",
    "generated_at": "2025-12-28T21:49:59.231952",
    "operation": "min",
    "seed": 55,
    "has_backward": true
  },
  "ir_backward": "void atom_cydtvt_9ad61039_cuda_kernel_backward(\n    wp::launch_bounds_t dim,\n    wp::array_t<wp::float32> var_values,\n    wp::array_t<wp::float32> var_result,\n    wp::array_t<wp::float32> adj_values,\n    wp::array_t<wp::float32> adj_result)\n{\n    wp::tile_shared_storage_t tile_mem;\n\n    for (size_t _idx = static_cast<size_t>(blockDim.x) * static_cast<size_t>(blockIdx.x) + static_cast<size_t>(threadIdx.x);\n         _idx < dim.size;\n         _idx += static_cast<size_t>(blockDim.x) * static_cast<size_t>(gridDim.x))\n    {\n            // reset shared memory allocator\n        wp::tile_shared_storage_t::init();\n\n        //---------\n        // primal vars\n        wp::int32 var_0;\n        const wp::int32 var_1 = 0;\n        wp::float32* var_2;\n        wp::float32 var_3;\n        wp::float32 var_4;\n        //---------\n        // dual vars\n        wp::int32 adj_0 = {};\n        wp::int32 adj_1 = {};\n        wp::float32 adj_2 = {};\n        wp::float32 adj_3 = {};\n        wp::float32 adj_4 = {};\n        //---------\n        // forward\n        // def atom_cydtvt(values: wp.array(dtype=float), result: wp.array(dtype=float)):         <L 4>\n        // tid = wp.tid()                                                                         <L 5>\n        var_0 = builtin_tid1d();\n        // wp.atomic_min(result, 0, values[tid])                                                  <L 6>\n        var_2 = wp::address(var_values, var_0);\n        var_4 = wp::load(var_2);\n        // var_3 = wp::atomic_min(var_result, var_1, var_4);\n        //---------\n        // reverse\n        wp::adj_atomic_min(var_result, var_1, var_4, adj_result, adj_1, adj_2, adj_3);\n        wp::adj_address(var_values, var_0, adj_values, adj_0, adj_2);\n        // adj: wp.atomic_min(result, 0, values[tid])                                             <L 6>\n        // adj: tid = wp.tid()                                                                    <L 5>\n        // adj: def atom_cydtvt(values: wp.array(dtype=float), result: wp.array(dtype=float)):    <L 4>\n        continue;\n    }\n}"
}
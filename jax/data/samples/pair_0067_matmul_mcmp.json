{
  "name": "matmul_mcmp",
  "python_source": "def matmul_mcmp(a, b):\n    \"\"\"Matrix multiplication of shapes (7,4) @ (4,10).\"\"\"\n    return jnp.dot(a, b)",
  "jaxpr": "{ lambda ; a:f32[7,4] b:f32[4,10]. let\n    c:f32[7,10] = dot_general[\n      dimension_numbers=(([1], [0]), ([], []))\n      preferred_element_type=float32\n    ] a b\n  in (c,) }",
  "stablehlo": "module @jit_matmul_mcmp attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {\n  func.func public @main(%arg0: tensor<7x4xf32>, %arg1: tensor<4x10xf32>) -> (tensor<7x10xf32> {jax.result_info = \"result\"}) {\n    %0 = stablehlo.dot_general %arg0, %arg1, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<7x4xf32>, tensor<4x10xf32>) -> tensor<7x10xf32>\n    return %0 : tensor<7x10xf32>\n  }\n}\n",
  "xla_hlo": "HloModule jit_matmul_mcmp, entry_computation_layout={(f32[7,4]{1,0}, f32[4,10]{1,0})->f32[7,10]{1,0}}\n\nENTRY main.1 {\n  a.1 = f32[7,4]{1,0} parameter(0)\n  b.1 = f32[4,10]{1,0} parameter(1)\n  ROOT dot_general.1 = f32[7,10]{1,0} dot(a.1, b.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n}\n\n",
  "input_shapes": [
    [
      7,
      4
    ],
    [
      4,
      10
    ]
  ],
  "output_shape": [
    7,
    10
  ]
}
{
  "name": "mean_vhde",
  "python_source": "def mean_vhde(x):\n    \"\"\"Mean reduction along axis 1.\"\"\"\n    return jnp.mean(x, axis=1)",
  "jaxpr": "{ lambda ; a:f32[12,11,7]. let\n    b:f32[12,7] = reduce_sum[axes=(1,) out_sharding=None] a\n    c:f32[12,7] = div b 11.0:f32[]\n  in (c,) }",
  "stablehlo": "module @jit_mean_vhde attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {\n  func.func public @main(%arg0: tensor<12x11x7xf32>) -> (tensor<12x7xf32> {jax.result_info = \"result\"}) {\n    %cst = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.add across dimensions = [1] : (tensor<12x11x7xf32>, tensor<f32>) -> tensor<12x7xf32>\n    %cst_0 = stablehlo.constant dense<1.100000e+01> : tensor<f32>\n    %1 = stablehlo.broadcast_in_dim %cst_0, dims = [] : (tensor<f32>) -> tensor<12x7xf32>\n    %2 = stablehlo.divide %0, %1 : tensor<12x7xf32>\n    return %2 : tensor<12x7xf32>\n  }\n}\n",
  "xla_hlo": "HloModule jit_mean_vhde, entry_computation_layout={(f32[12,11,7]{2,1,0})->f32[12,7]{1,0}}\n\nregion_0.1 {\n  reduce_sum.3 = f32[] parameter(0)\n  reduce_sum.4 = f32[] parameter(1)\n  ROOT reduce_sum.5 = f32[] add(reduce_sum.3, reduce_sum.4)\n}\n\nENTRY main.2 {\n  x.1 = f32[12,11,7]{2,1,0} parameter(0)\n  constant.3 = f32[] constant(0)\n  reduce_sum.7 = f32[12,7]{1,0} reduce(x.1, constant.3), dimensions={1}, to_apply=region_0.1\n  constant.2 = f32[] constant(11)\n  div.2 = f32[12,7]{1,0} broadcast(constant.2), dimensions={}\n  ROOT div.3 = f32[12,7]{1,0} divide(reduce_sum.7, div.2)\n}\n\n",
  "input_shapes": [
    [
      12,
      11,
      7
    ]
  ],
  "output_shape": [
    12,
    7
  ]
}
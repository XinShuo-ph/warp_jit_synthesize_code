{
  "name": "matmul_arwj",
  "python_source": "def matmul_arwj(a, b):\n    \"\"\"Matrix multiplication of shapes (15,10) @ (10,12).\"\"\"\n    return jnp.dot(a, b)",
  "jaxpr": "{ lambda ; a:f32[15,10] b:f32[10,12]. let\n    c:f32[15,12] = dot_general[\n      dimension_numbers=(([1], [0]), ([], []))\n      preferred_element_type=float32\n    ] a b\n  in (c,) }",
  "stablehlo": "module @jit_matmul_arwj attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {\n  func.func public @main(%arg0: tensor<15x10xf32>, %arg1: tensor<10x12xf32>) -> (tensor<15x12xf32> {jax.result_info = \"result\"}) {\n    %0 = stablehlo.dot_general %arg0, %arg1, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<15x10xf32>, tensor<10x12xf32>) -> tensor<15x12xf32>\n    return %0 : tensor<15x12xf32>\n  }\n}\n",
  "xla_hlo": "HloModule jit_matmul_arwj, entry_computation_layout={(f32[15,10]{1,0}, f32[10,12]{1,0})->f32[15,12]{1,0}}\n\nENTRY main.1 {\n  a.1 = f32[15,10]{1,0} parameter(0)\n  b.1 = f32[10,12]{1,0} parameter(1)\n  ROOT dot_general.1 = f32[15,12]{1,0} dot(a.1, b.1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n}\n\n",
  "input_shapes": [
    [
      15,
      10
    ],
    [
      10,
      12
    ]
  ],
  "output_shape": [
    15,
    12
  ]
}
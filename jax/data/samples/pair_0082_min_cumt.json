{
  "name": "min_cumt",
  "python_source": "def min_cumt(x):\n    \"\"\"Min reduction along axis 2.\"\"\"\n    return jnp.min(x, axis=2)",
  "jaxpr": "{ lambda ; a:f32[10,3,7,6]. let\n    b:f32[10,3,6] = reduce_min[axes=(2,)] a\n  in (b,) }",
  "stablehlo": "module @jit_min_cumt attributes {mhlo.num_partitions = 1 : i32, mhlo.num_replicas = 1 : i32} {\n  func.func public @main(%arg0: tensor<10x3x7x6xf32>) -> (tensor<10x3x6xf32> {jax.result_info = \"result\"}) {\n    %cst = stablehlo.constant dense<0x7F800000> : tensor<f32>\n    %0 = stablehlo.reduce(%arg0 init: %cst) applies stablehlo.minimum across dimensions = [2] : (tensor<10x3x7x6xf32>, tensor<f32>) -> tensor<10x3x6xf32>\n    return %0 : tensor<10x3x6xf32>\n  }\n}\n",
  "xla_hlo": "HloModule jit_min_cumt, entry_computation_layout={(f32[10,3,7,6]{3,2,1,0})->f32[10,3,6]{2,1,0}}\n\nregion_0.1 {\n  reduce_min.3 = f32[] parameter(0)\n  reduce_min.4 = f32[] parameter(1)\n  ROOT reduce_min.5 = f32[] minimum(reduce_min.3, reduce_min.4)\n}\n\nENTRY main.2 {\n  x.1 = f32[10,3,7,6]{3,2,1,0} parameter(0)\n  constant.1 = f32[] constant(inf)\n  ROOT reduce_min.7 = f32[10,3,6]{2,1,0} reduce(x.1, constant.1), dimensions={2}, to_apply=region_0.1\n}\n\n",
  "input_shapes": [
    [
      10,
      3,
      7,
      6
    ]
  ],
  "output_shape": [
    10,
    3,
    6
  ]
}